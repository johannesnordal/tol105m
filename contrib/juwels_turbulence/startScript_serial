#!/bin/bash

# General configuration of the job
#SBATCH --job-name=TorchTest
#SBATCH --account=deepext
#SBATCH --mail-user=
#SBATCH --mail-type=ALL
#SBATCH --output=job.out
#SBATCH --error=job.err
#SBATCH --time=04:00:00

# Configure the gateway daemon
# SBATCH --gw_num=1
# SBATCH --gw_psgwd_per_node=1

# Configure node and process count on the CM
#SBATCH --partition=dp-esb-ib
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=1
#SBATCH --exclusive
#SBATCH --gpus-per-node=1

# debug features
debug=true

# Echo job configuration
if [ "$debug" = true ] ; then
   echo "DEBUG: SLURM_JOB_NODELIST=$SLURM_JOB_NODELIST"
   echo "DEBUG: SLURM_NNODES=$SLURM_NNODES"
   echo "DEBUG: SLURM_NTASKS=$SLURM_NTASKS"
   echo "DEBUG: SLURM_TASKS_PER_NODE=$SLURM_TASKS_PER_NODE"
   echo "DEBUG: SLURM_SUBMIT_HOST=$SLURM_SUBMIT_HOST"
   echo "DEBUG: SLURM_NODEID=$SLURM_NODEID"
   echo "DEBUG: SLURM_LOCALID=$SLURM_LOCALID" 
   echo "DEBUG: SLURM_PROCID=$SLURM_PROCID"
fi

# some stuff
export NUM_NODES=1
export NUM_GPUS_PER_NODE=1
export NODE_RANK=0
export WORLD_SIZE=$(($NUM_NODES * $NUM_GPUS_PER_NODE))


# Set the environment
module --force purge
#module use $OTHERSTAGES
#ml Stages/2020
module load GCC
module load Python
#ml Stages/Devel-2019a GCC GCCcore/.8.3.0 PyTorch/1.4.0-GPU-Python-3.6.8 Intel ParaStationMPI/5.4.6-1-mt
ml PyTorch/1.1.0-GPU-Python-3.6.8
#module load Stages/2020
#module load ParaStationMPI/5.4.7-1-mt
# ml Stages/2020 GCC ParaStationMPI/5.4.7-1-mt 
# ml NCCL/2.8.3-1-CUDA-11.0 cuDNN/8.0.2.39-CUDA-11.0 Python
# ml mpi-settings/CUDA Python

# source env
# source your version for now
#source /work/deepext/sarma/aihpc-env/bin/activate
#source /p/project/prcoe12/RAISE/envAI_deepv/bin/activate
source /work/deepext/sarma/venv_p3/bin/activate
# sleep a sec
sleep 1

# Execute
srun python -u \
    Autoencoder_Turbulence_serial.py > log_`date +'%Y%m%d_%H%M%S'` 2>&1

